{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# libraries\n",
      "%pylab inline\n",
      "import gzip, cPickle\n",
      "import numpy as np\n",
      "from random import shuffle\n",
      "\n",
      "# methods\n",
      "def load_mnist():\n",
      "\tf = gzip.open('mnist.pkl.gz', 'rb')\n",
      "\tdata = cPickle.load(f)\n",
      "\tf.close()\n",
      "\treturn data\n",
      "\n",
      "\n",
      "def plot_digits(data, numcols, shape=(28,28)):\n",
      "    numdigits = data.shape[0]\n",
      "    numrows = int(numdigits/numcols)\n",
      "    for i in range(numdigits):\n",
      "        plt.subplot(numrows, numcols, i)\n",
      "        plt.axis('off')\n",
      "        plt.imshow(data[i].reshape(shape), interpolation='nearest', cmap='Greys')\n",
      "    plt.show()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 1.1 Gradient-based stochastic optimization\n",
      "## 1.1.1 Derive gradient computation equations\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$$\\mathcal{L}=\\sum\\limits_{n=1}^N\\mathcal{L}^{(n)}$$\n",
      "and \n",
      "$$\\mathcal{L}^{(n)}=\\ln(p(t=t_n \\;|\\; \\textbf{x}_n, \\textbf{b}, \\textbf{W})>0$$\n",
      "Hence, we can optimize $\\mathcal{L}$ for  every  data point separately.\n",
      "$$\\mathcal{L}^{(n)}\n",
      "=\\ln(p(t=t_n \\;|\\; \\textbf{x}_n, \\textbf{b}, \\textbf{W})\n",
      "=\\ln(q_n)-\\ln(Z)=x_n\\textbf{w}_{t_n}^T+b_{t_n}-\\ln(\\sum\\limits_j \\exp\\{x_n\\textbf{w}_{j}^T+b_{j}\\})$$\n",
      "\n",
      "\n",
      "\n",
      "$$ \\dfrac{\\partial\\mathcal{L}^{(n)} }{\\partial b_{i}}= \\delta_{t_ni}-\\dfrac{\\partial Z }{\\partial b_i}\\dfrac{\\partial \\ln(Z) }{\\partial Z}\n",
      "=\\delta_{t_ni}- \\dfrac{\\exp\\{\\textbf{x}_n^{T}\\textbf{w}_i+b_i\\}}{Z}$$\n",
      "\n",
      "$$ \\dfrac{\\partial\\mathcal{L}^{(n)}}{\\partial \\textbf{w}_i}\n",
      "= \\delta_{t_ni}\\textbf{x}_n-\\dfrac{\\partial Z }{\\partial \\textbf{w}_i}\\dfrac{\\partial \\ln(Z) }{\\partial Z}\n",
      "=\\delta_{t_ni}\\textbf{x}_n- \\dfrac{\\textbf{x}_n\\exp\\{\\textbf{x}_n^{T}\\textbf{w}_i+b_i\\}}{Z}\n",
      "=\\textbf{x}_n\\cdot\\dfrac{\\partial\\mathcal{L}^{(n)} }{\\partial b_i} $$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.1.2 Compute gradients of the log-likelihood"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def logreg_gradient(x, t, W, b):\n",
      "    M,J=W.shape\n",
      "    N=x.shape\n",
      "    grad_b=zeros(J)\n",
      "    grad_W=zeros((M,J))\n",
      "    # compute Z\n",
      "    Z=0\n",
      "    for j in xrange(J):\n",
      "        Z+=exp(np.dot(x,W[:,j].T)+b[j])\n",
      "    # compute grad_b\n",
      "    for j in xrange(J):\n",
      "        grad_b[j]=-exp(np.dot(x,W[:,j].T)+b[j])/Z\n",
      "    grad_b[t]+=1\n",
      "    # compute grad_W\n",
      "    for j in xrange(J):\n",
      "        grad_W[:,j]=x*grad_b[j]\n",
      "        \n",
      "    return grad_b, grad_W"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.1.3 Stochastic gradient descent"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sgd_iter(x_train, t_train, W, b):\n",
      "    M,J=W.shape\n",
      "    N,M=x_train.shape\n",
      "    eta=1E-4 #learning_rate\n",
      "    indices = np.arange(N,  dtype = int)\n",
      "    np.random.shuffle(indices)\n",
      "\n",
      "    # stochatic gradient decent\n",
      "    for n in indices:\n",
      "        grad_b, grad_W = logreg_gradient(x_train[n,:],t_train[n],W,b)\n",
      "        b+= eta*grad_b \n",
      "        W+= eta*grad_W\n",
      "    return W,b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 1.2 Train\n",
      "\n",
      "## 1.2.1 Train"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load data\n",
      "(x_train, t_train), (x_valid, t_valid), (x_test, t_test) = load_mnist()\n",
      "#initilaize W and b\n",
      "N,M=x_train.shape\n",
      "J=10\n",
      "b=zeros(J)#ask about that\n",
      "W=zeros((M,J))\n",
      "\n",
      "# some iterations\n",
      "for i in xrange(20):\n",
      "    W,b=sgd_iter(x_train, t_train, W, b)\n",
      "    # prediction with x_test and t_test\n",
      "    # calculate error_test\n",
      "    # prediction with x_valid and t_valid\n",
      "    # calculate error_valid\n",
      "    # plot error of training/ validation\n",
      "    \n",
      "    # Visulaze W, W[:,j] is one image\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.2.2 Visualize weights\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##1.2.3. Visualize the 8 hardest and 8 easiest digits\n",
      "Visualize the 8 digits in the validation set with the highest probability of the true class label under the model. Also plot the 8 digits that\n",
      "were assigned the lowest probability. Ask yourself if these results make sense.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. Multilayer perceptron\n",
      "$$\\mathcal{L}^{(n)}\n",
      "=\\ln(p(t=t_n \\;|\\; \\textbf{x}_n, \\textbf{b}, \\textbf{W})\n",
      "=\\ln(q_n)-\\ln(Z)=\\textbf{w}_{t_n}^T\\textbf{h}^{(n)}+b_{t_n}-\\ln(\\sum\\limits_j \\exp\\{x_n\\textbf{w}_{j}^T+b_{j}\\})$$\n",
      "\n",
      "$$h_l=\\sigma(\\textbf{v}_l^T\\textbf{x}_n+a_l)$$\n",
      "##2.1 Derive gradient equations\n",
      "\n",
      "In Part one our feature vector $\\phi(\\textbf{x})$ was equal to $\\textbf{x}$. Now we have the slightly more complicated case that\n",
      "$$\\phi(\\textbf{x})=\\textbf{h}(\\textbf{x}).$$\n",
      "However, in both cases $\\phi(\\textbf{x})$ is only a parameter when deriving $\\nabla_{\\textbf{b}} \\mathcal{L}^{(n)}$ and $\\nabla_{\\textbf{W}} \\mathcal{L}^{(n)}$. Thus, both terms are similarly to part 1 computed as follows:\n",
      "$$ \\dfrac{\\partial\\mathcal{L}^{(n)} }{\\partial b_{i}}= \\delta_{t_ni}-\\dfrac{\\partial Z }{\\partial b_i}\\dfrac{\\partial \\ln(Z) }{\\partial Z}\n",
      "=\\delta_{t_ni}- \\dfrac{\\exp\\{\\textbf{x}_n^{T}\\textbf{w}_i+b_i\\}}{Z}$$\n",
      "\n",
      "$$ \\dfrac{\\partial\\mathcal{L}^{(n)}}{\\partial \\textbf{w}_i}\n",
      "= \\delta_{t_ni}\\textbf{h}_n-\\dfrac{\\partial Z }{\\partial \\textbf{w}_i}\\dfrac{\\partial \\ln(Z) }{\\partial Z}\n",
      "=\\delta_{t_ni}\\textbf{h}_n- \\dfrac{\\textbf{x}_n\\exp\\{\\textbf{x}_n^{T}\\textbf{w}_i+b_i\\}}{Z}\n",
      "=\\textbf{h}^{(n)}\\cdot\\dfrac{\\partial\\mathcal{L}^{(n)} }{\\partial b_i} $$\n",
      "\n",
      "\n",
      "In the case of $\\textbf{a}$ and $\\textbf{V}$. We will have to have a closer look at the model.\n",
      "\n",
      "$$ \\dfrac{\\partial\\mathcal{L}^{(n)}}{\\partial a_l}\n",
      "= \\dfrac{\\partial\\mathcal{L}^{(n)}}{\\partial h^{(n)}_l}\\dfrac{\\partial h^{(n)}_l}{\\partial a_l}\n",
      "=\\delta^h_l \\dfrac{\\partial h^{(n)}_l}{\\partial r}\\dfrac{\\partial r}{\\partial a_l}\n",
      "=\\delta^h_l [\\sigma(r)(1-\\sigma(r))][1]\n",
      "=\\delta^h_l [\\sigma(\\textbf{v}_l^T\\textbf{x}_n+a_l)(1-\\sigma(\\textbf{v}_l^T\\textbf{x}_n+a_l))]\n",
      "= \\delta^h_l \\textbf{x}_n h_l(1-h_l)\n",
      "$$\n",
      "\n",
      "\n",
      "$$ \\dfrac{\\partial\\mathcal{L}^{(n)}}{\\partial \\textbf{v}_l}\n",
      "= \\dfrac{\\partial\\mathcal{L}^{(n)}}{\\partial h^{(n)}_l}\\dfrac{\\partial h^{(n)}_l}{\\partial \\textbf{v}_l}\n",
      "=\\delta^h_l \\dfrac{\\partial h^{(n)}_l}{\\partial r}\\dfrac{\\partial r}{\\partial \\textbf{v}_l}\n",
      "=\\delta^h_l [\\sigma(r)(1-\\sigma(r))][\\textbf{x}_n]\n",
      "=\\delta^h_l \\textbf{x}_n [\\sigma(\\textbf{v}_l^T\\textbf{x}_n+a_l)(1-\\sigma(\\textbf{v}_l^T\\textbf{x}_n+a_l))]\n",
      "= \\delta^h_l \\textbf{x}_n h_l(1-h_l)\n",
      "$$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.2 MAP optimization\n",
      "\n",
      "For this exercise we will define the following proberties for convinience\n",
      "\n",
      "$$\n",
      "\\tilde{x_n}=[1,x_n]^T\n",
      "$$$$\n",
      "\\tilde{h_l}=[1,h_l]^T\n",
      "$$$$\n",
      "\\tilde{w_j}=[b_j,w_j]^T\n",
      "$$$$\n",
      "\\tilde{v_l}=[a_l,v_l]^T\n",
      "$$\n",
      "\n",
      "Furthermore, we introduce the Gaussian priors with the simple scalar precition parameters $\\alpha$ and $\\beta$:\n",
      "$$p(\\tilde{w})=\\mathcal{N}(\\tilde{w}|\\mu_w,\\alpha^{-1}\\textbf{I})$$\n",
      "$$p(\\tilde{v})=\\mathcal{N}(\\tilde{v}|\\mu_v,\\beta^{-1}\\textbf{I})$$\n",
      "\n",
      "We know from Chapter 3 eq.(3.55) that when we assume a Gaussian prior with zero mean, the objective function is than given by \n",
      "$$E'=E-\\dfrac{\\alpha}{2}\\tilde{w}_j^T\\tilde{w}_j. $$\n",
      "\n",
      "\n",
      "We will now extend that concept. Consider that we are training multiple $\\tilde{w}_j$ and $\\tilde{v}_l$ with non zero mean. That means the equation generalizes to:\n",
      "\n",
      "$$E'=E-\\dfrac{\\alpha}{2}Tr\\{(\\tilde{W}-\\mu_wI)^T(\\tilde{W}-\\mu_wI)\\}-\\dfrac{\\beta}{2}Tr\\{(\\tilde{V}-\\mu_vI)^T(\\tilde{V}-\\mu_vI)\\}$$\n",
      "\n",
      "while we assume to have the same prior for all $w_j$ and $v_l$, respectively.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.3. Extra\n",
      "### 2.3.1. 10% bonus points: Implement and train a MLP\n",
      "You receive 10% bonus points if you succesfully implement a MLP model with a single hidden layer. Your code should include code to\n",
      "learn the parameters.\n",
      "### 2.3.2. 10% bonus points: Less than 150 misclassifications on the test set\n",
      "You receive an additional 10% bonus points if you manage to train a model with very high accuracy: at most 1.5% misclasified digits on\n",
      "the test set. Note that the test set contains 10000 digits, so you model should misclassify at most 150 digits. This should be achievable\n",
      "with a MLP model with one hidden layer. See results of various models at : h t : / a n l c n c m e d / n s / n e . t l\n",
      "tp/yn.eu.o/xbmitidxhm.\n",
      "To reach such a low accuracy, you probably need to have a very high   (many hidden units), probably \n",
      ", and apply a strong\n",
      "Gaussian prior on the weights. In this case you are allowed to use the validation set for training. You are allowed to add additional layers,\n",
      "and use convolutional networks, although that is probably not required to reach 1.5% misclassifications.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}